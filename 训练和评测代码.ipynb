{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "738eb218",
   "metadata": {},
   "source": [
    "# 下面是训练代码,训练过程中会进行测试."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e671c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "# import scipy.io.wavfile\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from dnn_models import MLP, flip\n",
    "from dnn_models import SincNet as CNN\n",
    "from data_io import ReadList, read_conf, str_to_bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4c628cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#随机数据然后拼接成一个batch\n",
    "def create_batches_rnd(batch_size, data_folder, wav_lst, N_snt, wlen, lab_dict, fact_amp):\n",
    "    # Initialization of the minibatch (batch_size,[0=>x_t,1=>x_t+N,1=>random_samp])\n",
    "    sig_batch = np.zeros([batch_size, wlen])\n",
    "    lab_batch = np.zeros(batch_size)\n",
    "\n",
    "    snt_id_arr = np.random.randint(N_snt, size=batch_size)\n",
    "\n",
    "    rand_amp_arr = np.random.uniform(1.0 - fact_amp, 1 + fact_amp, batch_size)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        # select a random sentence from the list\n",
    "        # [fs,signal]=scipy.io.wavfile.read(data_folder+wav_lst[snt_id_arr[i]])\n",
    "        # signal=signal.astype(float)/32768\n",
    "\n",
    "        [signal, fs] = sf.read(data_folder + wav_lst[snt_id_arr[i]])\n",
    "\n",
    "        # accesing to a random chunk=======随机抽取一块语音\n",
    "        snt_len = signal.shape[0]\n",
    "        snt_beg = np.random.randint(snt_len - wlen - 1)  # randint(0, snt_len-2*wlen-1)\n",
    "        snt_end = snt_beg + wlen\n",
    "\n",
    "        channels = len(signal.shape)\n",
    "        if channels == 2:\n",
    "            print('WARNING: stereo to mono: ' + data_folder + wav_lst[snt_id_arr[i]])\n",
    "            signal = signal[:, 0]\n",
    "        #把语音乘以一个随机倍数然后拼接到空白语音上.\n",
    "        sig_batch[i, :] = signal[snt_beg:snt_end] * rand_amp_arr[i]\n",
    "        lab_batch[i] = lab_dict[wav_lst[snt_id_arr[i]]]\n",
    "\n",
    "    inp = Variable(torch.from_numpy(sig_batch).float().contiguous())\n",
    "    lab = Variable(torch.from_numpy(lab_batch).float().contiguous())\n",
    "\n",
    "    return inp, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f10637a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.a object at 0x000001BAD0585860>\n",
      "1386\n"
     ]
    }
   ],
   "source": [
    "# 读取设置全部的超参数\n",
    "import configparser as ConfigParser\n",
    "from optparse import OptionParser\n",
    "import numpy as np\n",
    "# import scipy.io.wavfile\n",
    "import torch\n",
    "# Reading cfg file\n",
    "if 1:\n",
    "    class a():\n",
    "      pass\n",
    "    options=a()\n",
    "\n",
    "    options.cfg = 'cfg/SincNet_TIMIT.cfg'\n",
    "    cfg_file = options.cfg\n",
    "    Config = ConfigParser.ConfigParser()\n",
    "    Config.read(cfg_file)\n",
    "\n",
    "    # [data]\n",
    "    options.tr_lst = Config.get('data', 'tr_lst')\n",
    "    options.te_lst = Config.get('data', 'te_lst')\n",
    "    options.lab_dict = Config.get('data', 'lab_dict')\n",
    "    options.data_folder = Config.get('data', 'data_folder')\n",
    "    options.output_folder = Config.get('data', 'output_folder')\n",
    "    options.pt_file = Config.get('data', 'pt_file')\n",
    "\n",
    "    # [windowing]\n",
    "    options.fs = Config.get('windowing', 'fs')\n",
    "    options.cw_len = Config.get('windowing', 'cw_len')\n",
    "    options.cw_shift = Config.get('windowing', 'cw_shift')\n",
    "\n",
    "    # [cnn]\n",
    "    options.cnn_N_filt = Config.get('cnn', 'cnn_N_filt')\n",
    "    options.cnn_len_filt = Config.get('cnn', 'cnn_len_filt')\n",
    "    options.cnn_max_pool_len = Config.get('cnn', 'cnn_max_pool_len')\n",
    "    options.cnn_use_laynorm_inp = Config.get('cnn', 'cnn_use_laynorm_inp')\n",
    "    options.cnn_use_batchnorm_inp = Config.get('cnn', 'cnn_use_batchnorm_inp')\n",
    "    options.cnn_use_laynorm = Config.get('cnn', 'cnn_use_laynorm')\n",
    "    options.cnn_use_batchnorm = Config.get('cnn', 'cnn_use_batchnorm')\n",
    "    options.cnn_act = Config.get('cnn', 'cnn_act')\n",
    "    options.cnn_drop = Config.get('cnn', 'cnn_drop')\n",
    "\n",
    "    # [dnn]\n",
    "    options.fc_lay = Config.get('dnn', 'fc_lay')\n",
    "    options.fc_drop = Config.get('dnn', 'fc_drop')\n",
    "    options.fc_use_laynorm_inp = Config.get('dnn', 'fc_use_laynorm_inp')\n",
    "    options.fc_use_batchnorm_inp = Config.get('dnn', 'fc_use_batchnorm_inp')\n",
    "    options.fc_use_batchnorm = Config.get('dnn', 'fc_use_batchnorm')\n",
    "    options.fc_use_laynorm = Config.get('dnn', 'fc_use_laynorm')\n",
    "    options.fc_act = Config.get('dnn', 'fc_act')\n",
    "\n",
    "    # [class]\n",
    "    options.class_lay = Config.get('class', 'class_lay')\n",
    "    options.class_drop = Config.get('class', 'class_drop')\n",
    "    options.class_use_laynorm_inp = Config.get('class', 'class_use_laynorm_inp')\n",
    "    options.class_use_batchnorm_inp = Config.get('class', 'class_use_batchnorm_inp')\n",
    "    options.class_use_batchnorm = Config.get('class', 'class_use_batchnorm')\n",
    "    options.class_use_laynorm = Config.get('class', 'class_use_laynorm')\n",
    "    options.class_act = Config.get('class', 'class_act')\n",
    "\n",
    "    # [optimization]\n",
    "    options.lr = Config.get('optimization', 'lr')\n",
    "    options.batch_size = Config.get('optimization', 'batch_size')\n",
    "    options.N_epochs = Config.get('optimization', 'N_epochs')\n",
    "    options.N_batches = Config.get('optimization', 'N_batches')\n",
    "    options.N_eval_epoch = Config.get('optimization', 'N_eval_epoch')\n",
    "    options.seed = Config.get('optimization', 'seed')\n",
    "print(options)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# [data]\n",
    "tr_lst = options.tr_lst\n",
    "te_lst = options.te_lst\n",
    "pt_file = options.pt_file\n",
    "class_dict_file = options.lab_dict\n",
    "data_folder = options.data_folder + '/'\n",
    "output_folder = options.output_folder\n",
    "\n",
    "# [windowing]\n",
    "fs = int(options.fs)\n",
    "cw_len = int(options.cw_len)\n",
    "cw_shift = int(options.cw_shift)\n",
    "\n",
    "# [cnn]\n",
    "cnn_N_filt = list(map(int, options.cnn_N_filt.split(',')))\n",
    "cnn_len_filt = list(map(int, options.cnn_len_filt.split(',')))\n",
    "cnn_max_pool_len = list(map(int, options.cnn_max_pool_len.split(',')))\n",
    "cnn_use_laynorm_inp = str_to_bool(options.cnn_use_laynorm_inp)\n",
    "cnn_use_batchnorm_inp = str_to_bool(options.cnn_use_batchnorm_inp)\n",
    "cnn_use_laynorm = list(map(str_to_bool, options.cnn_use_laynorm.split(',')))\n",
    "cnn_use_batchnorm = list(map(str_to_bool, options.cnn_use_batchnorm.split(',')))\n",
    "cnn_act = list(map(str, options.cnn_act.split(',')))\n",
    "cnn_drop = list(map(float, options.cnn_drop.split(',')))\n",
    "\n",
    "# [dnn]\n",
    "fc_lay = list(map(int, options.fc_lay.split(',')))\n",
    "fc_drop = list(map(float, options.fc_drop.split(',')))\n",
    "fc_use_laynorm_inp = str_to_bool(options.fc_use_laynorm_inp)\n",
    "fc_use_batchnorm_inp = str_to_bool(options.fc_use_batchnorm_inp)\n",
    "fc_use_batchnorm = list(map(str_to_bool, options.fc_use_batchnorm.split(',')))\n",
    "fc_use_laynorm = list(map(str_to_bool, options.fc_use_laynorm.split(',')))\n",
    "fc_act = list(map(str, options.fc_act.split(',')))\n",
    "\n",
    "# [class]\n",
    "class_lay = list(map(int, options.class_lay.split(',')))\n",
    "class_drop = list(map(float, options.class_drop.split(',')))\n",
    "class_use_laynorm_inp = str_to_bool(options.class_use_laynorm_inp)\n",
    "class_use_batchnorm_inp = str_to_bool(options.class_use_batchnorm_inp)\n",
    "class_use_batchnorm = list(map(str_to_bool, options.class_use_batchnorm.split(',')))\n",
    "class_use_laynorm = list(map(str_to_bool, options.class_use_laynorm.split(',')))\n",
    "class_act = list(map(str, options.class_act.split(',')))\n",
    "\n",
    "# [optimization]\n",
    "lr = float(options.lr)\n",
    "batch_size = int(options.batch_size)\n",
    "N_epochs = int(options.N_epochs)\n",
    "N_batches = int(options.N_batches)\n",
    "N_eval_epoch = int(options.N_eval_epoch)\n",
    "seed = int(options.seed)\n",
    "\n",
    "# training list\n",
    "wav_lst_tr = ReadList(tr_lst)\n",
    "wav_lst_tr = [i.upper() for i in wav_lst_tr]\n",
    "snt_tr = len(wav_lst_tr)\n",
    "\n",
    "# test list\n",
    "wav_lst_te = ReadList(te_lst)\n",
    "wav_lst_te = [i.upper() for i in wav_lst_te]\n",
    "snt_te = len(wav_lst_te)\n",
    "print(snt_te)\n",
    "\n",
    "\n",
    "# Folder creation\n",
    "try:\n",
    "    os.stat(output_folder)\n",
    "except:\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "# setting seed\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# loss function\n",
    "cost = nn.NLLLoss()\n",
    "\n",
    "# Converting context and shift in samples\n",
    "wlen = int(fs * cw_len / 1000.00)  # 取多长的序列\n",
    "wshift = int(fs * cw_shift / 1000.00)\n",
    "\n",
    "# Batch_dev\n",
    "Batch_dev = 128\n",
    "\n",
    "# Feature extractor CNN\n",
    "CNN_arch = {'input_dim': wlen,\n",
    "            'fs': fs,\n",
    "            'cnn_N_filt': cnn_N_filt,\n",
    "            'cnn_len_filt': cnn_len_filt,\n",
    "            'cnn_max_pool_len': cnn_max_pool_len,\n",
    "            'cnn_use_laynorm_inp': cnn_use_laynorm_inp,\n",
    "            'cnn_use_batchnorm_inp': cnn_use_batchnorm_inp,\n",
    "            'cnn_use_laynorm': cnn_use_laynorm,\n",
    "            'cnn_use_batchnorm': cnn_use_batchnorm,\n",
    "            'cnn_act': cnn_act,\n",
    "            'cnn_drop': cnn_drop,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec937b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建网络结构\n",
    "\n",
    "CNN_net = CNN(CNN_arch)\n",
    "# CNN_net.cuda()\n",
    "\n",
    "# Loading label dictionary\n",
    "lab_dict = np.load(class_dict_file, allow_pickle=True).item()\n",
    "lab_dict2 = {}\n",
    "for i in lab_dict:\n",
    "    lab_dict2[i.upper()] = lab_dict[i]\n",
    "lab_dict = lab_dict2\n",
    "\n",
    "# 这里面标签的含义是, 按照人来标的. 总共3696个语音.400多个人. 每一个人用一个int表示.从0--461\n",
    "with open('for_debug', 'w') as f:\n",
    "    f.write(str(lab_dict))\n",
    "\n",
    "DNN1_arch = {'input_dim': CNN_net.out_dim,\n",
    "             'fc_lay': fc_lay,\n",
    "             'fc_drop': fc_drop,\n",
    "             'fc_use_batchnorm': fc_use_batchnorm,\n",
    "             'fc_use_laynorm': fc_use_laynorm,\n",
    "             'fc_use_laynorm_inp': fc_use_laynorm_inp,\n",
    "             'fc_use_batchnorm_inp': fc_use_batchnorm_inp,\n",
    "             'fc_act': fc_act,\n",
    "             }\n",
    "\n",
    "DNN1_net = MLP(DNN1_arch)\n",
    "# DNN1_net.cuda()\n",
    "\n",
    "\n",
    "DNN2_arch = {'input_dim': fc_lay[-1],\n",
    "             'fc_lay': class_lay,\n",
    "             'fc_drop': class_drop,\n",
    "             'fc_use_batchnorm': class_use_batchnorm,\n",
    "             'fc_use_laynorm': class_use_laynorm,\n",
    "             'fc_use_laynorm_inp': class_use_laynorm_inp,\n",
    "             'fc_use_batchnorm_inp': class_use_batchnorm_inp,\n",
    "             'fc_act': class_act,\n",
    "             }\n",
    "\n",
    "DNN2_net = MLP(DNN2_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6712f6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载上次训练完的模型\n",
      "加载模型的路径是 exp/SincNet_TIMIT/model_raw.pkl\n",
      "加载失败\n"
     ]
    }
   ],
   "source": [
    "# 进行训练,打印每一个epoch的 err率\n",
    "#=============接着训练.......直接读取之前训练好的权重做finetune即可.\n",
    "print('加载上次训练完的模型')\n",
    "try:\n",
    "    pt_file=output_folder + '/model_raw.pkl'\n",
    "    pt_file='exp/SincNet_TIMIT/model_raw.pkl'\n",
    "    print('加载模型的路径是',pt_file)\n",
    "    \n",
    "    if pt_file != 'none':\n",
    "        checkpoint_load = torch.load(pt_file)\n",
    "        CNN_net.load_state_dict(checkpoint_load['CNN_model_par'])\n",
    "        DNN1_net.load_state_dict(checkpoint_load['DNN1_model_par'])\n",
    "        DNN2_net.load_state_dict(checkpoint_load['DNN2_model_par'])\n",
    "except:\n",
    "    print('加载失败')\n",
    "    pass\n",
    "\n",
    "optimizer_CNN = optim.RMSprop(CNN_net.parameters(), lr=lr, alpha=0.95, eps=1e-8)\n",
    "optimizer_DNN1 = optim.RMSprop(DNN1_net.parameters(), lr=lr, alpha=0.95, eps=1e-8)\n",
    "optimizer_DNN2 = optim.RMSprop(DNN2_net.parameters(), lr=lr, alpha=0.95, eps=1e-8)\n",
    "\n",
    "for epoch in range(N_epochs):\n",
    "\n",
    "    test_flag = 0\n",
    "    CNN_net.train()\n",
    "    DNN1_net.train()\n",
    "    DNN2_net.train()\n",
    "\n",
    "    loss_sum = 0\n",
    "    err_sum = 0\n",
    "\n",
    "    for i in range(N_batches):\n",
    "        [inp, lab] = create_batches_rnd(batch_size, data_folder, wav_lst_tr, snt_tr, wlen, lab_dict, 0.2)\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # print('shiyongdeshi', device)\n",
    "        CNN_net = CNN_net.to(device)\n",
    "        DNN1_net = DNN1_net.to(device)\n",
    "        DNN2_net = DNN2_net.to(device)\n",
    "        inp = inp.to(device)\n",
    "        lab = lab.to(device)\n",
    "\n",
    "        pout = DNN2_net(DNN1_net(CNN_net(inp)))  # 这里面就是自定义化的cnn 叫sinconv\n",
    "\n",
    "        pred = torch.max(pout, dim=1)[1]\n",
    "        loss = cost(pout, lab.long())\n",
    "        err = torch.mean((pred != lab.long()).float())\n",
    "        if i%1==0:\n",
    "             print(\"当前epoch的loss和err\", loss, err)\n",
    "\n",
    "        optimizer_CNN.zero_grad()\n",
    "        optimizer_DNN1.zero_grad()\n",
    "        optimizer_DNN2.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_CNN.step()\n",
    "        optimizer_DNN1.step()\n",
    "        optimizer_DNN2.step()\n",
    "\n",
    "        loss_sum = loss_sum + loss.detach()\n",
    "        err_sum = err_sum + err.detach()\n",
    "\n",
    "    loss_tot = loss_sum / N_batches\n",
    "    err_tot = err_sum / N_batches\n",
    "    print('训练完一个epoch,保存模型')\n",
    "    checkpoint = {'CNN_model_par': CNN_net.state_dict(),\n",
    "                  'DNN1_model_par': DNN1_net.state_dict(),\n",
    "                  'DNN2_model_par': DNN2_net.state_dict(),\n",
    "                  }\n",
    "    torch.save(checkpoint, output_folder + '/model_raw.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d49eeb",
   "metadata": {},
   "source": [
    "加载上次训练完的模型========GPU上运行结果:\n",
    "当前epoch的loss和err tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward>) tensor(0.0027, device='cuda:0')\n",
    "当前epoch的loss和err tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward>) tensor(0.0009, device='cuda:0')\n",
    "当前epoch的loss和err tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward>) tensor(0.0036, device='cuda:0')\n",
    "当前epoch的loss和err tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward>) tensor(0.0018, device='cuda:0')\n",
    "当前epoch的loss和err tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward>) tensor(0.0027, device='cuda:0')\n",
    "当前epoch的loss和err tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward>) tensor(0.0036, device='cuda:0')\n",
    "当前epoch的loss和err tensor(0.0134, device='cuda:0', grad_fn=<NllLossBackward>) tensor(0.0027, device='cuda:0')\n",
    "当前epoch的loss和err tensor(0.0206, device='cuda:0', grad_fn=<NllLossBackward>) tensor(0.0036, device='cuda:0')\n",
    "当前epoch的loss和err tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward>) tensor(0.0009, device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc346bdd",
   "metadata": {},
   "source": [
    "看到最终准确率百分之99.8左右比传统的cnn结构更好"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
