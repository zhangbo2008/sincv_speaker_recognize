{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3e2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#核心网络SincNet的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 论文中的sincNet的加速版本.利用的函数的对称性,代码真正使用的就是这个算法.对应论文里面 chapter2 里面的公式3到8\n",
    "class SincConv_fast(nn.Module):\n",
    "    \"\"\"Sinc-based convolution\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : `int`\n",
    "        Number of input channels. Must be 1.\n",
    "    out_channels : `int`\n",
    "        Number of filters.\n",
    "    kernel_size : `int`\n",
    "        Filter length.\n",
    "    sample_rate : `int`, optional\n",
    "        Sample rate. Defaults to 16000.\n",
    "    Usage\n",
    "    -----\n",
    "    See `torch.nn.Conv1d`\n",
    "    Reference\n",
    "    ---------\n",
    "    Mirco Ravanelli, Yoshua Bengio,\n",
    "    \"Speaker Recognition from raw waveform with SincNet\".\n",
    "    https://arxiv.org/abs/1808.00158\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def to_mel(hz):\n",
    "        return 2595 * np.log10(1 + hz / 700)\n",
    "\n",
    "    @staticmethod\n",
    "    def to_hz(mel):\n",
    "        return 700 * (10 ** (mel / 2595) - 1)\n",
    "\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1,\n",
    "                 stride=1, padding=0, dilation=1, bias=False, groups=1, min_low_hz=50, min_band_hz=50):\n",
    "        # kerel_size:251 就是论文中公式8里面的L.\n",
    "        super(SincConv_fast, self).__init__()\n",
    "\n",
    "        if in_channels != 1:\n",
    "            # msg = (f'SincConv only support one input channel '\n",
    "            #       f'(here, in_channels = {in_channels:d}).')\n",
    "            msg = \"SincConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
    "        if kernel_size % 2 == 0:\n",
    "            self.kernel_size = self.kernel_size + 1\n",
    "\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "        if bias:\n",
    "            raise ValueError('SincConv does not support bias.')\n",
    "        if groups > 1:\n",
    "            raise ValueError('SincConv does not support groups.')\n",
    "\n",
    "        self.sample_rate = sample_rate\n",
    "        self.min_low_hz = min_low_hz\n",
    "        self.min_band_hz = min_band_hz\n",
    "\n",
    "        # initialize filterbanks such that they are equally spaced in Mel scale\n",
    "        low_hz = 30\n",
    "        high_hz = self.sample_rate / 2 - (self.min_low_hz + self.min_band_hz)\n",
    "\n",
    "        mel = np.linspace(self.to_mel(low_hz),\n",
    "                          self.to_mel(high_hz),\n",
    "                          self.out_channels + 1)  # 转化为mel频率.变成81个\n",
    "        hz = self.to_hz(mel)  # 低频率用mel进行初始化.\n",
    "\n",
    "        # filter lower frequency (out_channels, 1)\n",
    "        self.low_hz_ = nn.Parameter(torch.Tensor(hz[:-1]).view(-1, 1))  # 只要前80个.\n",
    "\n",
    "        # filter frequency band (out_channels, 1)\n",
    "        self.band_hz_ = nn.Parameter(torch.Tensor(np.diff(hz)).view(-1, 1))  # 差分的频率. 就是后一个减前一个.用的是hz做的差分,所以最后还是80个.\n",
    "\n",
    "        # Hamming window\n",
    "        # self.window_ = torch.hamming_window(self.kernel_size)\n",
    "        n_lin = torch.linspace(0, (self.kernel_size / 2) - 1, steps=int(\n",
    "            (self.kernel_size / 2)))  # computing only half of the window,      steps:切分的数量.\n",
    "        self.window_ = 0.54 - 0.46 * torch.cos(2 * math.pi * n_lin / self.kernel_size)\n",
    "\n",
    "        # (1, kernel_size/2)\n",
    "        n = (self.kernel_size - 1) / 2.0\n",
    "        self.n_ = 2 * math.pi * torch.arange(-n, 0).view(1,\n",
    "                                                         -1) / self.sample_rate  # Due to symmetry, I only need half of the time axes======一个常数.下面公式需要用到.论文中的n是时间,我们这里面输入的n是帧.所以要除以sample_rate.\n",
    "\n",
    "    # ===========这个地方是因为,数学上的卷积是 x*h是x里面第一个跟h里面最后一个乘都乘完sum. torch里面是按照顺序的.所以需要这里面用-n来改变顺序.!!!!!!!!!!!!!!!!!!!不懂的可以看这个博客:https://zhuanlan.zhihu.com/p/30086163\n",
    "\n",
    "    def forward(self, waveforms):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        waveforms : `torch.Tensor` (batch_size, 1, n_samples)\n",
    "            Batch of waveforms.\n",
    "        Returns\n",
    "        -------\n",
    "        features : `torch.Tensor` (batch_size, out_channels, n_samples_out)\n",
    "            Batch of sinc filters activations.\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_ = self.n_.to(waveforms.device)\n",
    "\n",
    "        self.window_ = self.window_.to(waveforms.device)\n",
    "\n",
    "        low = self.min_low_hz + torch.abs(self.low_hz_)  # 最低50hez加上个每一个间隔.\n",
    "        # 根据论文来,不能大于采样率一半.采样定理.\n",
    "        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_), self.min_low_hz, self.sample_rate / 2)\n",
    "        band = (high - low)[:, 0]\n",
    "\n",
    "        f_times_t_low = torch.matmul(low, self.n_)  # 论文里面的低通和高通filter 弄成2个矩阵.\n",
    "        f_times_t_high = torch.matmul(high, self.n_)\n",
    "\n",
    "        band_pass_left = ((torch.sin(f_times_t_high) - torch.sin(f_times_t_low)) / (\n",
    "                self.n_ / 2)) * self.window_  # Equivalent of Eq.4 of the reference paper (SPEAKER RECOGNITION FROM RAW WAVEFORM WITH SINCNET). I just have expanded the sinc and simplified the terms. This way I avoid several useless computations.\n",
    "        band_pass_center = 2 * band.view(-1, 1)\n",
    "        band_pass_right = torch.flip(band_pass_left, dims=[1])  # 对称. flip一下. 第二个维度进行flip.也就是每一个列向量进行逆转.\n",
    "\n",
    "        band_pass = torch.cat([band_pass_left, band_pass_center, band_pass_right], dim=1)\n",
    "\n",
    "        band_pass = band_pass / (2 * band[:, None])  # 除以最大值归一化,最大值就是中间这个数值.\n",
    "\n",
    "        self.filters = (band_pass).view(  # 论文里面计算的g函数.\n",
    "            self.out_channels, 1, self.kernel_size)\n",
    "\n",
    "        return F.conv1d(waveforms, self.filters, stride=self.stride,\n",
    "                        padding=self.padding, dilation=self.dilation,\n",
    "                        bias=None, groups=1)  # 窗口大小251,每一次步长是1.输出特征维度是80.\n",
    "# 输入数据waveforms, L=7的话, filters是 3,2,1,0,-1,-2,-3\n",
    "# 因为对称性,左边3==-3,  2==-2  1==-1  因为g 关于n是一个偶函数. 虽然公式里面n是正数,但是因为周期性.定义域可以向后移动半个周期.\n",
    "\n",
    "# 数据索引是 0,1,2,3,4,5,6的话.==========这样conv1d之后每一个位置的索引和都是3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
